{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd8e263-ed12-44e9-9568-d0781afa11a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from hs_gimme.constants.clients import ClientsNames\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ACCOUNTS = {\n",
    "    ClientsNames.ANTALYA,\n",
    "    ClientsNames.PORTO,\n",
    "    ClientsNames.SEATTLE,\n",
    "    ClientsNames.MOSCOW,\n",
    "    ClientsNames.ATHENS,\n",
    "    ClientsNames.CANCUN,\n",
    "    ClientsNames.INDIANA,\n",
    "    ClientsNames.ARIZONA,\n",
    "    ClientsNames.OXFORD,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25b5955-942e-4355-bc09-053b8b6b4f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "req_fields =  ['job_department',\n",
    "              'country',\n",
    "               'external_job_band',\n",
    "               'external_recruiters',\n",
    "               'top_category',\n",
    "               'sub_category',\n",
    "               'job_education',\n",
    "               'seniority_level',\n",
    "               'min_years_of_relevant_experience',\n",
    "               'max_years_of_relevant_experience',\n",
    "               'max_salary',\n",
    "               'job_type',\n",
    "               'is_visa_required',\n",
    "               'is_remote_location', \n",
    "               'external_status',\n",
    "               'industry',\n",
    "               'open_date',\n",
    "               'past_candidates_distribution_date',\n",
    "               'is_recent_grad', \n",
    "               'is_intern',\n",
    "               '_created_at',\n",
    "               'date_posted',\n",
    "               'job_create_date',\n",
    "               'last_edit_date',\n",
    "               'recruiter_roles',\n",
    "               'recruiting_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb62b7f-445a-438a-81c8-79e64224aa69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_recommendation_status(row):\n",
    "    if row['dismissed_reason'] in {'Candidate invited to apply', \n",
    "                                   'Qualified but candidate not interested at this time',\n",
    "                                   'Qualified but candidate could not be reached',\n",
    "                                   'Candidate invited to apply, other: Candidate invited to apply'}:\n",
    "        return 'contacted'\n",
    "    \n",
    "    if row['dismissed_reason'] in {'other: not needed', \n",
    "                                   'other: This position is not posted externally. It is posted Internally only and is intended for a promotion for an Internal employee.', \n",
    "                                   'other: not needed right now',\n",
    "                                   'In process in another req',\n",
    "                                   'Current Employee',\n",
    "                                   'other: not needed right now'}:\n",
    "        return 'other'\n",
    "    \n",
    "    return row['recommendation_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fa49ea-f518-41c5-ac6f-11882edd3c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-05-19T15:24:05.807217Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMongos instances selected     \u001b[0m \u001b[36menvironment\u001b[0m=\u001b[35mlocal\u001b[0m \u001b[36mfile_path\u001b[0m=\u001b[35m/Users/dima/hiredscore/gimme/hs_gimme/db_facade/connection_string_builder.py\u001b[0m \u001b[36mfunction_name\u001b[0m=\u001b[35mget_selected_mongos_instances\u001b[0m \u001b[36mhostname\u001b[0m=\u001b[35mDima-Shulga-MacBook-Pro\u001b[0m \u001b[36mhosts\u001b[0m=\u001b[35m['applicativedb-prod-mongos-4.omcomcom.com', 'applicativedb-prod-mongos-0.omcomcom.com']\u001b[0m \u001b[36mline_number\u001b[0m=\u001b[35m38\u001b[0m \u001b[36mmodule\u001b[0m=\u001b[35mhs_gimme.db_facade.connection_string_builder\u001b[0m \u001b[36mpid\u001b[0m=\u001b[35m2589\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "actions = []\n",
    "reqs = {}\n",
    "for i, account in enumerate(ACCOUNTS):\n",
    "    \n",
    "    mongo = gmcdb('production', account.lower())\n",
    "    recs = list(mongo.recommended_candidate.find({'_created_at': {'$gt': datetime(2024, 2, 6)}}, ['req_id', \n",
    "                                                                                                  'applied_recipes', \n",
    "                                                                                                  'recommendation_status',\n",
    "                                                                                                  'dismissed_reason',\n",
    "                                                                                                  '_updated_at', \n",
    "                                                                                                  '_created_at', \n",
    "                                                                                                  'is_from_dynamic_fetch',\n",
    "                                                                                                  'current_talent_id', \n",
    "                                                                                                  'removed_date']))\n",
    "    \n",
    "    \n",
    "    act = list(mongo.dynamic_fetch_action.find({'created_at': {'$gt': datetime(2024, 2, 6)}}))\n",
    "    actions += act\n",
    "    \n",
    "    req_ids = list({r['req_id'] for r in recs if 'req_id' in r})\n",
    "    \n",
    "    \n",
    "    for req in mongo.req.find({'_id': {'$in': req_ids}}, req_fields):\n",
    "        reqs[req['_id']] = req\n",
    "    \n",
    "    \n",
    "    print(i, '/', len(ACCOUNTS), account, len(recs), Counter([r.get('applied_recipes') for r in recs]))\n",
    "\n",
    "    for r in recs:\n",
    "        r.update({'account_id': account})\n",
    "        data.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3fe6f-23e3-4d3f-95a0-81364dccf105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df['recommendation_status'] = df.apply(fix_recommendation_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d2a3d-7528-4f23-b063-3e518b052e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['recommendation_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0a6ea-f9ef-4137-bb6b-8323e1f8a7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[~df['recommendation_status'].isin({'new', 'other'}) & ~df['is_from_dynamic_fetch'].fillna(False)].dropna(subset=['applied_recipes'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3180b6d-4c3c-434d-8f76-7d96e9c3e080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in req_fields:\n",
    "    df[f] = df['req_id'].apply(lambda x: reqs[x].get(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb962a-b7d8-406d-983a-1f56a4c4f2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['is_positive'] = df['recommendation_status'].isin({'contacted', 'shared_with_hm', 'shared_with_recruiter', 'profile_sent'})\n",
    "df['user'] = df['recruiter_roles'].apply(lambda x: x['recruiter'])\n",
    "df['is_from_dynamic_fetch'] = df['is_from_dynamic_fetch'].fillna(False)\n",
    "df['is_new_algo'] = df['applied_recipes'] == 'base_fetch'\n",
    "df['min_years_of_relevant_experience_scaled'] =  (df['min_years_of_relevant_experience'] - df['min_years_of_relevant_experience'].min()) / (df['min_years_of_relevant_experience'].max() - df['min_years_of_relevant_experience'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ec93c-512d-4a49-960d-a28105b4beb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['account_id'] = df['account_id'].apply(lambda x: ['all', x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d9908-af0d-405f-9fce-fe0d70f7e3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.explode('account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e0556-76b9-49ed-b273-7d47787b2585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54984e4e-2f53-4e8c-ac1e-b78ce13777f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb = ['account_id', 'applied_recipes']\n",
    "#gb = ['account_id', 'top_category', 'applied_recipes']\n",
    "gdf = df.groupby(gb + ['recommendation_status'])['_id'].count()\n",
    "udf = gdf.unstack().fillna(0)\n",
    "udf['num_of_reqs'] = df.groupby(gb)['req_id'].nunique()\n",
    "udf['num_of_users'] = df.groupby(gb)['user'].nunique()\n",
    "udf['viewed'] += 1\n",
    "udf['contacted'] += 1\n",
    "udf['total'] = udf['contacted'] + udf['dismissed'] + udf['viewed']\n",
    "udf['rate'] = udf['contacted'] / udf['total']\n",
    "xdf = udf.unstack()#.dropna(subset=[('total', 'base_fetch'), ('total', 'base_fetch&legacy_query_fetch_for_ab_test')])\n",
    "xdf['ratio'] = xdf[('rate', 'base_fetch')] / xdf[('rate', 'base_fetch&legacy_query_fetch_for_ab_test')]\n",
    "xdf.dropna(subset=[('ratio', '')])\n",
    "#xdf = xdf[(xdf[('total', 'base_fetch')] > 20) & (xdf[('total', 'base_fetch&legacy_query_fetch_for_ab_test')] > 20)]\n",
    "\n",
    "xdf.reset_index().groupby([('account_id', '')]).agg(num_of_recommendations_new=(('total', 'base_fetch') , 'sum'), \n",
    "                                                    num_of_recommendations_old=(('total', 'base_fetch&legacy_query_fetch_for_ab_test') , 'sum'),\n",
    "                                                    num_of_reqs_new=(('num_of_reqs', 'base_fetch') , 'sum'), \n",
    "                                                    num_of_reqs_old=(('num_of_reqs', 'base_fetch&legacy_query_fetch_for_ab_test') , 'sum'),\n",
    "                                                    num_of_users_new=(('num_of_users', 'base_fetch') , 'sum'), \n",
    "                                                    num_of_users_old=(('num_of_users', 'base_fetch&legacy_query_fetch_for_ab_test') , 'sum'),\n",
    "                                                    adjusted_change_median=(('ratio', ''), 'median'),\n",
    "                                                    # adjusted_change_25q=(('ratio', ''), lambda x: x.quantile(0.25)),\n",
    "                                                    # adjusted_change_75q=(('ratio', ''), lambda x: x.quantile(0.75)),\n",
    "                                                    adjusted_change_mean=(('ratio', ''), 'mean'),  \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad5cd3-49ef-4241-9cb3-bc29c1feea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf.to_csv('~/Downloads/athens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c99dac-da4a-445f-850a-14c1004b729c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xdf.boxplot(column='ratio', by='account_id', figsize=(13, 5))\n",
    "plt.plot([1]*10, color='red', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0134b4-c62e-49b6-9c5a-2c1291d274c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('ab_test_results_mar_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377a7c0-5ae5-49c1-8c6e-5f04bf820ab3",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc252c-38f2-47c9-93eb-2ffa6bc09f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for account, account_df in list(df.groupby('account_id')):\n",
    "    bootstrap_ratios = []\n",
    "    for _ in range(1000):\n",
    "        gdf = account_df.sample(n=len(account_df), replace=True).groupby(gb + ['recommendation_status'])['_id'].count()\n",
    "        udf = gdf.unstack().fillna(0)\n",
    "        udf['num_of_reqs'] = df.groupby(gb)['req_id'].nunique()\n",
    "        udf['num_of_users'] = df.groupby(gb)['user'].nunique()\n",
    "        if 'viewed' not in udf:\n",
    "            udf['viewed'] = 0\n",
    "            \n",
    "        if 'contacted' not in udf:\n",
    "            udf['contacted'] = 0\n",
    "            \n",
    "        if 'dismissed' not in udf:\n",
    "            udf['dismissed'] = 0\n",
    "            \n",
    "        udf['viewed'] += 1\n",
    "        udf['contacted'] += 1\n",
    "        udf['total'] = udf['contacted'] + udf['dismissed'] + udf['viewed']\n",
    "        udf['rate'] = udf['contacted'] / udf['total']\n",
    "        account_xdf = udf.unstack().dropna(subset=[('total', 'base_fetch'), ('total', 'base_fetch&legacy_query_fetch_for_ab_test')])\n",
    "        account_xdf['ratio'] = account_xdf[('rate', 'base_fetch')] / account_xdf[('rate', 'base_fetch&legacy_query_fetch_for_ab_test')]\n",
    "        account_xdf = account_xdf.dropna(subset=[('ratio', '')])\n",
    "        #account_xdf = account_xdf[(account_xdf[('total', 'base_fetch')] > 20) & (account_xdf[('total', 'base_fetch&legacy_query_fetch_for_ab_test')] > 20)]\n",
    "        \n",
    "        m = account_xdf['ratio'].dropna().median()\n",
    "        \n",
    "        if not math.isinf(m):\n",
    "            bootstrap_ratios.append(m)\n",
    "    print(account, len(account_df), 'actions')\n",
    "    print('Mean of median:', np.mean(bootstrap_ratios))\n",
    "    confidence_interval = np.percentile(bootstrap_ratios, [5, 95])\n",
    "    print(\"Bootstrap 90% Confidence Interval:\", confidence_interval)\n",
    "    print(round(np.mean(bootstrap_ratios), 2), [round(x, 2) for x in confidence_interval])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b458a-faba-4e09-8140-37c5a36829a7",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328e5e5-801d-4c6c-a244-da17622de083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = ['account_id', 'top_category',  'job_education']\n",
    "for account, account_df in list(df.groupby('account_id')) + [('ALL', df)]:\n",
    "    xdf = account_df\n",
    "    model_df = pd.get_dummies(xdf[conf]).astype(int)\n",
    "    to_drop = []\n",
    "\n",
    "    for f in conf:\n",
    "        to_drop.append([c for c in model_df.columns if f in c][0])\n",
    "\n",
    "    print('Dropping:', to_drop)\n",
    "    model_df = model_df.drop(to_drop, axis=1)\n",
    "    #model_df = pd.get_dummies(account_df[['account_id']])\n",
    "    model_df['is_new_algo'] = xdf['is_new_algo'].astype(int)\n",
    "    model_df['min_years_of_relevant_experience_scaled'] = xdf['min_years_of_relevant_experience_scaled'].fillna(1)\n",
    "    #model_df =  lr_df[['is_new_algo']].astype(int)\n",
    "    model_df = sm.add_constant(model_df)\n",
    "\n",
    "    \n",
    "\n",
    "    res = sm.Logit(xdf['is_positive'], model_df, maxiter=200).fit()\n",
    "    print(f\"OR={np.exp(res.params['is_new_algo'])}, p={res.pvalues['is_new_algo']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccedee-4c52-40cd-b72a-46db21c8ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for account_id, xdf in df.groupby('account_id'):\n",
    "    if account_id == 'all':\n",
    "        continue\n",
    "        xdf = df[df['account_id'] != 'all']\n",
    "    conf = ['account_id', 'sub_category', 'user', 'job_education']\n",
    "    model_df = pd.get_dummies(xdf[conf]).astype(int)\n",
    "    \n",
    "    model_df['is_new_algo'] = xdf['is_new_algo'].astype(int)\n",
    "    model_df['min_years_of_relevant_experience_scaled'] = xdf['min_years_of_relevant_experience_scaled'].fillna(1)\n",
    "    #model_df =  lr_df[['is_new_algo']].astype(int)\n",
    "    model_df = sm.add_constant(model_df)\n",
    "    print(account_id)\n",
    "    fitted = False\n",
    "    while not fitted:\n",
    "        try:\n",
    "            res = sm.Logit(xdf['is_positive'], model_df).fit(disp=0)\n",
    "            fitted = True\n",
    "            results.append({'account_id': account, 'odds_ratio':  np.exp(res.params['is_new_algo']), 'p_value': res.pvalues['is_new_algo']})\n",
    "        except Exception as e:\n",
    "            print(e, model_df.shape)\n",
    "            \n",
    "            VIF = [variance_inflation_factor(model_df.values, i) for i in range(model_df.shape[1])]\n",
    "            to_drop = list(sorted(zip(model_df.columns, VIF), key=lambda x: x[1], reverse=1))[0]\n",
    "            model_df = model_df.drop(to_drop[0], axis=1)\n",
    "           \n",
    "            print('dropping', to_drop, 'new shape', model_df.shape)\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be766c-0ded-4627-bfb7-f43a13b5c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d35a6-fd4c-4102-ae6c-6a2b1925d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_constant(model_df)  # your_dataframe should contain only predictor variables\n",
    "VIF = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "for c, v in sorted(zip(model_df.columns, VIF), key=lambda x: x[1], reverse=1):\n",
    "    print(c, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0a443-3ad0-4efd-9876-c17d74ab14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = 'seattle'\n",
    "\n",
    "        \n",
    "\n",
    "print(f\"{account_id}, OR={np.exp(res.params['is_new_algo'])}, p={res.pvalues['is_new_algo']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebc9f9-6aa4-45f5-b5c7-6f01c2ce96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3fa294-a508-4c5b-9ea4-21b44c1bc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a360102-1dac-4635-bfd0-21c19a5a8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = ['account_id', 'top_category', 'user', 'job_education']\n",
    "xdf = df[df['account_id'] != 'all']\n",
    "model_df = pd.get_dummies(xdf[conf]).astype(int)\n",
    "to_drop = []\n",
    "\n",
    "for f in conf:\n",
    "    to_drop.append([c for c in model_df.columns if f in c][0])\n",
    "\n",
    "print('Dropping:', to_drop)\n",
    "model_df = model_df.drop(to_drop, axis=1)\n",
    "#model_df = pd.get_dummies(account_df[['account_id']])\n",
    "model_df['is_new_algo'] = xdf['is_new_algo'].astype(int)\n",
    "model_df['min_years_of_relevant_experience_scaled'] = xdf['min_years_of_relevant_experience_scaled'].fillna(1)\n",
    "#model_df =  lr_df[['is_new_algo']].astype(int)\n",
    "model_df = sm.add_constant(model_df)\n",
    "\n",
    "\n",
    "\n",
    "res = sm.Logit(xdf['is_positive'], model_df, maxiter=200).fit()\n",
    "print(f\"OR={np.exp(res.params['is_new_algo'])}, p={res.pvalues['is_new_algo']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb8f24-1913-4baa-a652-c3dcd46406e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
